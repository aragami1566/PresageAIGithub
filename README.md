# Medical Assistant Call Service

This project is a FastAPI-based server that integrates with several services to create an automated medical assistant. It uses:
- **FastAPI** for the API endpoints and WebSocket handling.
- **Twilio** for managing voice calls and text-to-speech (TTS).
- **Azure Cognitive Services Speech SDK** for real-time speech-to-text (STT) conversion.
- **DeepInfraLLM** for generating natural language responses and conversation summaries.
- **python-dotenv** to manage environment variables.

The service listens for incoming call events, processes voice data through Azure’s Speech Recognition, and interacts with a language model to generate responses. The responses are then played back using Twilio’s TTS capabilities.

## Prerequisites

- **Python 3.8+** – Ensure you have Python installed.
- A valid **Twilio account** with a Twilio development phone number.
- An **Azure Speech** subscription key and region.
- An API key and base URL for **DeepInfraLLM**.
- [Pipenv](https://pipenv.pypa.io/) or **pip** to manage Python packages.

## Installation

1. **Clone the Repository:**

   ```bash
   git clone https://github.com/yourusername/medical-assistant-call-service.git
   cd medical-assistant-call-service
   ```

2. **Create a Virtual Environment:**

   Using venv:

   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows use `venv\Scripts\activate`
   ```

3. **Install Dependencies:**

   Ensure you have a `requirements.txt` file that includes the following external libraries:

   ```txt
   fastapi
   uvicorn
   twilio
   python-dotenv
   azure-cognitiveservices-speech
   numpy
   nltk
   nest_asyncio
   ```

   Then install the requirements:

   ```bash
   pip install -r requirements.txt
   ```

4. **Configure Environment Variables:**

   Create a `.env` file in the project root with the following keys:

   ```env
   # Azure Speech Configuration
   speech_api=<your_azure_speech_subscription_key>
   region=<your_azure_region>

   # DeepInfra LLM Configuration
   deepinfra_key=<your_deepinfra_api_key>
   deepinfra_base_url=<your_deepinfra_base_url>

   # Twilio Configuration
   TWILIO_ACCOUNT_SID=<your_twilio_account_sid>
   TWILIO_AUTH_TOKEN=<your_twilio_auth_token>
   TWILIO_CALLER_NUMBER=<your_twilio_phone_number>

   # Public Host (e.g., provided by ngrok for local testing)
   PUBLIC_HOST=<your_public_url>

   # (Optional) Port for the FastAPI server
   PORT=5050
   ```

## Running the Service

1. **Start the Server:**

   The service uses uvicorn to run the FastAPI application. You can start the server with:

   ```bash
   uvicorn main:app --host 0.0.0.0 --port 5050
   ```

   If you need to use asynchronous utilities like nest_asyncio (for running in a notebook or interactive session), ensure that it’s imported and applied as shown in the code.

2. **Testing with Twilio:**

   - **Setup Twilio Dev Phone:**

     Log in to your Twilio Console and configure your development phone number.
     Set the Voice & Fax webhook for the phone number to point to your public host URL (e.g., https://<your_public_url>/incoming-call).

   - **Make a Test Call:**

     Use the `/make-call` endpoint to initiate an outgoing call. For example, you can test via curl or Postman:

     ```bash
     curl -X POST http://localhost:5050/make-call \
       -H "Content-Type: application/json" \
       -d '{"target_phone": "+33123456789"}'
     ```

     The server will use Twilio to place the call and connect the media stream for speech recognition and response generation.

## Monitoring and Logs

The server logs important events such as recognized text, LLM responses, and call status. Check the terminal output to debug or monitor the service.

## How It Works

1. **Voice Recognition:** The service leverages Azure’s Speech SDK to process incoming audio via a WebSocket. The recognized speech text is then sanitized and sent to the DeepInfraLLM for processing.
2. **Response Generation:** A response is generated by the LLM based on the current conversation context and a predetermined conversation plan.
3. **Call Management:** Twilio is used to manage the call lifecycle, including TTS responses, call redirection, and summarization upon call completion.
4. **Session Management:** The service maintains a session per call, tracking conversation steps, context, and generating a conversation summary after the call ends.

## Additional Notes

- **NLTK Data:** If you use NLTK functionalities (e.g., punkt tokenizer), ensure you download the required NLTK data:

  ```python
  import nltk
  nltk.download('punkt')
  ```

- **Local Testing:** For local development, you can use ngrok to expose your local server to the internet, so Twilio’s webhook can reach your FastAPI endpoints.